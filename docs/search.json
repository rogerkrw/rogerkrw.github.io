[
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "✅ FASES 1 E 2 CONCLUÍDAS - Home com bio completa + 3 posts recentes ✓ - Primeiro blog post publicado ✓ - Estrutura de blog funcional ✓ - Deploy em produção ✓\n\n\n\n\n\nObjetivo: Backup da versão com blog preenchido com posts de exemplo.\nStatus: Disponível para testes e referência futura.\n\n\n\nObjetivo: Adicionar formulário de assinatura Brevo no blog para captação de e-mails.\nStatus: FUNCIONAL - Aguardando configuração de disparo de e-mails no Brevo\nO que contém: - Formulário Brevo em subscribe.html - Integração via margin-header no blog.qmd - reCAPTCHA removido (causava erro no localhost) - Tamanho médio (350px de largura)\nPendências antes do merge: - Configurar disparo automático de e-mails no Brevo - Configurar domínio autorizado para reCAPTCHA (opcional) - Testar fluxo completo de assinatura\nQuando fazer merge: - Quando sistema de e-mails estiver configurado no Brevo - Em momento estratégico para começar captação de leads\n\n\n\n\nHome (index.qmd)\n├─ Bio completa com detalhes\n├─ Seção \"Posts recentes\"\n└─ Últimos 3 posts (apenas títulos, sem data/imagem)\n\nBlog (blog.qmd)\n└─ Todos os posts (listagem em tabela)\n\n\n\nInício | Blog\n\n\n\nMetadados Obrigatórios (Front Matter):\n---\ntitle: Título do Post\nauthor: Rogério Kreidlow\ndate: YYYY-MM-DD\ndescription: Breve descrição para cards e SEO\nimage: imagem-principal.png\ncategories:\n  - Categoria1\n  - Categoria2\nkeywords:\n  - palavra-chave1\n  - palavra-chave2\ntoc: true\n---\nExemplo: Primeiro Post Publicado - Arquivo: blog/2025-10-20-o-risco-do-achatamento-linguistico-cultural-dos-llms/2025-10-20-o-risco-do-achatamento-linguistico-cultural-dos-llms.md - Status: ✓ Publicado - Imagens: 2 (principais + citações)\n\n\n\n\nCriar estrutura de blog\nAtualizar index.qmd com listagem de posts\nConfigurar metadados de posts (YAML front matter)\nAdicionar primeiro blog post com conteúdo real\nConfigurar CSS para limpar apresentação (sem headers, filtros, etc)\nPublicar em produção (main branch)\nAtualizar .gitignore para rastrear posts e imagens\n\n\n\n\n\n\n\nConfigurar disparo de e-mails no Brevo\nTestar fluxo completo de assinatura\n(Opcional) Configurar reCAPTCHA para domínio de produção\nFazer merge de add-subscription em main\nPublicar formulário de assinatura\n\n\n\n\n\nInstalar extensão quarto-social-share\nConfigurar botões de compartilhamento (Twitter, LinkedIn, Facebook)\nTestar em todos os posts\nPublicar\n\n\n\n\n\n\n\nExtensão: quarto-social-share (GitHub: schochastics/quarto-social-share)\nUso:\nquarto add schochastics/quarto-social-share\nConfiguração no YAML:\n---\ntitle: \"Post Title\"\nformat:\n  html:\n    social-share: true\n    share-buttons: [twitter, facebook, linkedin]\n---\nRedes suportadas: Twitter, Facebook, LinkedIn, Email, etc.\nStatus: Pesquisado, pronto para implementação\n\n\n\n\n\nCLAUDE.md está ignorado no .gitignore (arquivo de planejamento/referência)\nTemplate usado: trestles (página “about” da home)\nHome usa page-layout: full e toc: false para largura completa\nCSS customizado em theme-light.scss:\n\n.quarto-listing-table thead { display: none !important; } - Oculta headers de tabela nas listagens\nGarante apresentação limpa da listagem de posts\n\nPosts são armazenados em blog/YYYY-MM-DD-slug/arquivo.md com metadados YAML\nImagens dos posts devem estar no mesmo diretório\nRenderização em docs/ pronta para deploy"
  },
  {
    "objectID": "CLAUDE.html#status-atual",
    "href": "CLAUDE.html#status-atual",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "✅ FASES 1 E 2 CONCLUÍDAS - Home com bio completa + 3 posts recentes ✓ - Primeiro blog post publicado ✓ - Estrutura de blog funcional ✓ - Deploy em produção ✓"
  },
  {
    "objectID": "CLAUDE.html#branches-de-desenvolvimento",
    "href": "CLAUDE.html#branches-de-desenvolvimento",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Objetivo: Backup da versão com blog preenchido com posts de exemplo.\nStatus: Disponível para testes e referência futura.\n\n\n\nObjetivo: Adicionar formulário de assinatura Brevo no blog para captação de e-mails.\nStatus: FUNCIONAL - Aguardando configuração de disparo de e-mails no Brevo\nO que contém: - Formulário Brevo em subscribe.html - Integração via margin-header no blog.qmd - reCAPTCHA removido (causava erro no localhost) - Tamanho médio (350px de largura)\nPendências antes do merge: - Configurar disparo automático de e-mails no Brevo - Configurar domínio autorizado para reCAPTCHA (opcional) - Testar fluxo completo de assinatura\nQuando fazer merge: - Quando sistema de e-mails estiver configurado no Brevo - Em momento estratégico para começar captação de leads"
  },
  {
    "objectID": "CLAUDE.html#estrutura-de-navegação",
    "href": "CLAUDE.html#estrutura-de-navegação",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Home (index.qmd)\n├─ Bio completa com detalhes\n├─ Seção \"Posts recentes\"\n└─ Últimos 3 posts (apenas títulos, sem data/imagem)\n\nBlog (blog.qmd)\n└─ Todos os posts (listagem em tabela)"
  },
  {
    "objectID": "CLAUDE.html#navbar",
    "href": "CLAUDE.html#navbar",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Início | Blog"
  },
  {
    "objectID": "CLAUDE.html#estrutura-de-posts",
    "href": "CLAUDE.html#estrutura-de-posts",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Metadados Obrigatórios (Front Matter):\n---\ntitle: Título do Post\nauthor: Rogério Kreidlow\ndate: YYYY-MM-DD\ndescription: Breve descrição para cards e SEO\nimage: imagem-principal.png\ncategories:\n  - Categoria1\n  - Categoria2\nkeywords:\n  - palavra-chave1\n  - palavra-chave2\ntoc: true\n---\nExemplo: Primeiro Post Publicado - Arquivo: blog/2025-10-20-o-risco-do-achatamento-linguistico-cultural-dos-llms/2025-10-20-o-risco-do-achatamento-linguistico-cultural-dos-llms.md - Status: ✓ Publicado - Imagens: 2 (principais + citações)"
  },
  {
    "objectID": "CLAUDE.html#tarefas-concluídas",
    "href": "CLAUDE.html#tarefas-concluídas",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Criar estrutura de blog\nAtualizar index.qmd com listagem de posts\nConfigurar metadados de posts (YAML front matter)\nAdicionar primeiro blog post com conteúdo real\nConfigurar CSS para limpar apresentação (sem headers, filtros, etc)\nPublicar em produção (main branch)\nAtualizar .gitignore para rastrear posts e imagens"
  },
  {
    "objectID": "CLAUDE.html#plano-de-ação-futuro",
    "href": "CLAUDE.html#plano-de-ação-futuro",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Configurar disparo de e-mails no Brevo\nTestar fluxo completo de assinatura\n(Opcional) Configurar reCAPTCHA para domínio de produção\nFazer merge de add-subscription em main\nPublicar formulário de assinatura\n\n\n\n\n\nInstalar extensão quarto-social-share\nConfigurar botões de compartilhamento (Twitter, LinkedIn, Facebook)\nTestar em todos os posts\nPublicar"
  },
  {
    "objectID": "CLAUDE.html#extensões-e-recursos",
    "href": "CLAUDE.html#extensões-e-recursos",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "Extensão: quarto-social-share (GitHub: schochastics/quarto-social-share)\nUso:\nquarto add schochastics/quarto-social-share\nConfiguração no YAML:\n---\ntitle: \"Post Title\"\nformat:\n  html:\n    social-share: true\n    share-buttons: [twitter, facebook, linkedin]\n---\nRedes suportadas: Twitter, Facebook, LinkedIn, Email, etc.\nStatus: Pesquisado, pronto para implementação"
  },
  {
    "objectID": "CLAUDE.html#notas-técnicas",
    "href": "CLAUDE.html#notas-técnicas",
    "title": "Projeto: Redesign do Site - rogerkrw.github.io",
    "section": "",
    "text": "CLAUDE.md está ignorado no .gitignore (arquivo de planejamento/referência)\nTemplate usado: trestles (página “about” da home)\nHome usa page-layout: full e toc: false para largura completa\nCSS customizado em theme-light.scss:\n\n.quarto-listing-table thead { display: none !important; } - Oculta headers de tabela nas listagens\nGarante apresentação limpa da listagem de posts\n\nPosts são armazenados em blog/YYYY-MM-DD-slug/arquivo.md com metadados YAML\nImagens dos posts devem estar no mesmo diretório\nRenderização em docs/ pronta para deploy"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "O risco do “achatamento” linguístico-cultural dos LLMs\n\n\nSabe a sensação de que IAs escrevem em português, mas parecem pensar em inglês? Fiz um apanhado de estudos e dados para entender por que isso ocorre e suas possíveis consequências.\n\n\n\n\n\nOct 20, 2025\n\n\nRogério Kreidlow\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rogério Kreidlow",
    "section": "",
    "text": "Olá, sou Rogério Kreidlow e este é meu site pessoal.\nComo Head de Expansão da BeTalent, atuo tanto na prospecção e no relacionamento com clientes quanto na condução estratégica de PoCs de IA e discoveries de produto. Também faço a gestão de marketing e participo das decisões de board da empresa.\nEntre em contato\nAlém disso:\nINTJ-A no Myers-Briggs e C no DISC. Gosto de explorar conhecimentos e de construir, com palavras ou códigos."
  },
  {
    "objectID": "index.html#posts-recentes",
    "href": "index.html#posts-recentes",
    "title": "Rogério Kreidlow",
    "section": "Posts recentes",
    "text": "Posts recentes"
  },
  {
    "objectID": "blog/2025-10-20-achatamento-linguistico-cultural-llms/index.html",
    "href": "blog/2025-10-20-achatamento-linguistico-cultural-llms/index.html",
    "title": "O risco do “achatamento” linguístico-cultural dos LLMs",
    "section": "",
    "text": "Figure 1: Quanto maior a distância cultural dos EUA, menor a correlação entre respostas do GPT e o pensamento humano. Fonte: PsyArXiv Preprints\n\n\n\nHá algum tempo vi o gráfico que ilustra este artigo em um post de Cezar Taurion no LinkedIn, em que ele compartilhava outro post de Keith McNulty.\nApós me deter um pouco na imagem e ver rapidamente o estudo que deu origem a ela, lembro de ter elaborado uma hipótese mais ou menos assim: o fato de IAs como o ChatGPT e similares “pensarem” e “responderem” majoritariamente a partir do inglês (mesmo que traduzindo a outros idiomas) não pode enviesar a nós e a novas gerações a pensar e responder cada vez mais “em inglês” (não na língua em si, mas com a carga cultural de países onde o inglês é falado)? Não há risco de um processo de aculturamento, padronização, homogeneização, “achatamento” sócio-cognitivo, em detrimento de diversidade cultural, linguística, étnica?”\nTaurion, que questiona a confiança efusiva na IA generativa, diz no post:\n\n“O mundo não se limita ao Vale do Silício…” — Cezar Taurion.\n\nE McNulty, em tradução livre:\n\n“Este artigo publicado no ano passado por biólogos evolutivos de Harvard indica que — quando usado para tarefas cognitivas típicas — a similaridade entre respostas de modelos LLMs e respostas humanas diminui à medida que nos afastamos das grandes economias ocidentais ‘semelhantes aos EUA’. Isso levanta questões sobre se podemos generalizar globalmente conclusões sobre o uso seguro e produtivo da tecnologia de IA integrada em processos de trabalho. […]” — Keith McNulty.\n\nO print da postagem, para referência:\n\n\n\n\n\n\nFigure 2: Postagem de Cezar Taurion compartilhando a de Keith McNulty, que citou o artigo. Fonte: LinkedIn\n\n\n\n\nO estudo me chamou a atenção porque confirmava o que eu já intuía no uso quase diário de LLMs para escrita: havia sempre incômodos com termos, construções frasais, gerúndios, nuances, que não eram uma maneira “natural” de eu pensar e escrever em português do Brasil. Causavam fricção, incômodo. Não é um achado revelador e provavelmente você também já tenha tido o mesmo incômodo ou chegado à mesma constatação.\nE nem falo de termos como o “crucial” do GPT-3.5, que, de tão banalizado, surtia praticamente o efeito oposto, de nada mais ter importância. Qualquer “nariz de cera” (início de frase no estilo “encheção de linguiça”, que LLMs usam bastante), como “me fale sobre escovar os dentes todos os dias”, resultava em algo como: “Escovar os dentes todos os dias é um hábito crucial para…”. A evolução do GPT-4 e outros modelos ao menos parece ter melhorado tal comportamento.\nMas sempre sobram termos e construções como:\n\n“em constante evolução” (exemplo: “o mercado de trabalho em 2025 está em constante evolução…”);\n“ressoar” (“o importante é que esses conselhos ressoem em você”);\n“certifique-se de”, principalmente em listas de tarefas, com voz no imperativo (“certifique-se de ter preenchido todos os campos…”);\n“incluindo” para quaisquer locuções substantivas (exemplo: “[…] todos os departamentos da empresa, incluindo vendas, marketing e RH.”);\n“significativo”, no mesmo sentido de “crucial”;\ngerúndios que alongam sentenças (exemplo de uma típica frase de LLM: “a implementação do novo sistema representou um avanço significativo, permitindo…”);\nadjetivos desnecessários (o “significativo”, o “crucial”, entre vários outros);\ne por aí segue.\n\nIsso, é claro, para não falar de erros irritantes, como a mania de capitalizar todas as palavras em títulos ou itens de lista e em capitalizar a primeira palavra após dois-pontos, mesmo quando não seguem a regra.\nÉ claro que se você fornecer textos com seu estilo, LLMs irão mimetizá-los. Mas aí lidamos com outras consequências, como o modelo enviesar para aquela abordagem, adotar quase ipsis litteris a mesma construção do texto fornecido e aumentar de forma até caricata certas características.\nE mesmo isso ainda obriga a escrever um “manual” na tentativa de o modelo não adotar um tom que soa sempre a texto de marketing ou copywriting. Do contrário, é comum ele tender a destacar e “vender” qualquer assunto, por mais irrelevante que seja ou quando se quer uma abordagem mais neutra, sem qualificações.\n\nO paper “Which Humans?” (“Quais humanos?”, em tradução livre), que contém o gráfico que ilustra esse artigo, basicamente compara o desempenho de LLMs com o comportamento humano em testes psicológicos e ressalta a falta de diversidade cultural no treinamento dos LLMs.\nMetodologicamente, usa outro estudo chamado “World Values Survey (WVS)”, que coletou respostas de 94.278 indivíduos de 65 nações, para comparar respostas do GPT com as de grupos humanos.\nFoi, então, feita uma análise de “cluster hierárquico”, o que mostrou que o GPT estava mais próximo dos EUA e mais distante de culturas como as do Oriente Médio e da Ásia Central (a distância no eixo X). E uma correlação inversa foi encontrada entre a distância cultural dos Estados Unidos e a semelhança GPT-humano (a linha preta).\nUma das conclusões do estudo, portanto, é que o desempenho dos LLMs em tarefas cognitivas e psicológicas se assemelha mais ao de pessoas de sociedades “WEIRD” (“Western, Educated, Industrialized, Rich, and Democratic” ou “Ocidental, Educado, Industrializado, Rico e Democrático”, em tradução livre) e diminui à medida que se distancia dessas populações.\nPara nota rápida, WEIRD é um conceito que surgiu em um paper intitulado “The neglected 95%: why American psychology needs to become less American” (“Os 95% negligenciados: por que a psicologia americana precisa se tornar menos americana”), de Jeffrey J. Arnett, de 2008.\nNo estudo, Arnett argumenta que a pesquisa em Psicologia publicada nos periódicos da American Psychological Association (APA) se concentrava excessivamente em amostras americanas, que representam menos de 5% da população mundial.\nOu seja, a abordagem resulta em uma compreensão não representativa da psicologia humana, já que 95% da população global vive em condições culturais e socioeconômicas bem diferentes.\nÉ mais ou menos como tentar classificar todos os humanos a partir da ótica geracional que o marketing criou, dos baby boomers, X, millennials, Z, alfa, entre outras. Provavelmente, não fará muito sentido para entender povos esquimós, curdos, uigures ou guajajaras brasileiros.\nO gráfico em si, para entendimento nos detalhes, mostra:\n\nno eixo X (horizontal), a distância cultural de países em relação aos Estados Unidos (quanto maior o valor, mais diferente culturalmente é o país);\nno eixo Y (vertical), a correlação entre GPT e humanos (quanto maior, mais similaridade entre o desempenho do LLM e o modo de pensar daqueles humanos).\n\nA linha preta mostra correlação negativa (r = -0,7), o que significa que quanto mais distante culturalmente um país está dos EUA, pior o GPT performa se comparado à forma de pensar e se expressar das pessoas daquele país.\nNa prática, países culturalmente próximos aos EUA, como Austrália, Canadá e Reino Unido, têm alta correlação entre GPT e humanos (~0,85). Já países como Alemanha, Japão e Coreia do Sul ficam em uma faixa média (~0,78-0,8). E países culturalmente distantes (Paquistão, Líbia, Egito) apresentam correlações menores (~0,62-0,7).\nQual o motivo disso? Bastaria um exercício dedutivo mental para respondermos. Em quais dados LLMs como o GPT foram treinados? Web, principalmente Wikipedia, periódicos, livros. Qual o idioma predominante na web? Inglês, sobretudo americano. Mesmo chutando, você acertaria.\nResultado: o GPT tem um viés cultural alinhado com o inglês e toda a cultura que o fala e o molda no dia a dia, a qual, não há como negar, é uma cultura ocidentalizada, formalmente educada, industrializada, rica e — alguns questionarão — democrática.\n\nPesquisando manualmente e com ajuda de deep research de vários LLMs, não há nenhuma fonte oficial e cabal de qual a proporção de idiomas presentes em cada LLM mainstream. O fato de a maioria dos grandes modelos ter parado de compartilhar papers detalhados, por questões de concorrência e segredo industrial, após o GPT-3, em 2020, tornou esse campo mais especulativo do que exato.\nDe qualquer modo, não é difícil deduzir que o inglês seja a língua predominante na maioria dos conjuntos de dados de treinamentos. Basta fazer alguma extrapolação por fontes comuns e populares de dados.\nUma das principais dessas fontes é o Common Crawl, organização sem fins lucrativos que, desde 2008, faz web scraping (raspagem de dados) da internet mensalmente e disponibiliza seus dados de forma pública.\nNo site da instituição, é informado que 250 bilhões de páginas web foram raspadas em 18 anos e que de 3 a 5 bilhões de páginas são adicionadas por mês. No relatório de julho de 2025, por exemplo, a instituição obteve conteúdo de 2,42 bilhões de páginas web ou 419 TB (Terabytes) de conteúdo não compactado.\nConforme os dados de julho, disponíveis no GitHub, o inglês está presente em 44,6% dos conteúdos coletados. O segundo colocado é o russo, com apenas 5,8%, seguido do chinês (5,59%), alemão (5,58%) e japonês (5,27%). O português representa 2,16% do total.\nA proporção do inglês caiu 1,46% entre os dois últimos levantamentos, enquanto outras línguas vêm crescendo vagarosamente. Exemplos: chinês (+4,59%), japonês (+5,24%), italiano (+10,3%) e persa (41,14%), embora todos longe de equilibrar a predominância do inglês.\nVale ressaltar, porém, que o Common Crawl é apenas um dos muitos datasets massivos disponíveis. Há outros usados para treinamentos de modelos, além de versões otimizadas deles e, cada vez mais, dados sintéticos — gerados pelos próprios LLMs, por heurísticas ou por regras determinísticas para suprir a falta de dados de alta qualidade necessária às IAs.\nNem seria necessário ir tão longe para verificar os números. Só o fato da maioria dos artigos científicos (papers) serem escritos em inglês dá uma dimensão da proporção do idioma. A própria Wikipédia é uma boa bússola: 63,6 milhões de páginas são em inglês, contra 19,5 milhões do segundo colocado, o vietnamita.\n(Se você tem curiosidade sobre quantos dados haveria disponível para treinamento de LLMs no mundo, um post de 2024 deste site se propôs a fazer tal exercício. Não é científico, mas as ideias são bem referenciadas e logicamente construídas.)\nHá ainda outra questão em relação ao inglês e outros idiomas nos LLMs: consumo de tokens. Token, para entendimento rápido, é a menor unidade de texto que um modelo de IA “entende”. É um “pedaço” de uma palavra ou um caractere. Para que uma IA processe texto, ela precisa convertê-lo em números, e tokens servem a isso.\nPara um exemplo simplório, na frase “Olá, mundo!”, um tokenizador (ferramenta usada para converter textos em tokens) pode quebrar “Olá,” em “Olá” e “,”, e “mundo!” em “mundo” e “!”. Cada parte recebe um número no vocabulário do modelo, o que permite que a IA trabalhe com o texto como matrizes numéricas multidimensionais.\nEm inglês, com base na análise na maioria dos tokenizadores, uma palavra corresponde a 0,75 token. Em outros idiomas, a tendência é a correspondência ser maior, o que significa que modelos têm de “gastar” mais tokens para responder às entradas.\nPara o português do Brasil, é consenso que cada palavra corresponde a 1,5 token (este post no Reddit de 2023 calculava 1,9). O número aumenta em línguas como as asiáticas, da Índia, russo, grego e outras. Se formos olhar pelo lado de custos, é mais “caro” para um LLM genérico falar em outras línguas do que o inglês, o que pode reforçar ainda mais a comunicação na “língua-mãe” da tecnologia.\n\nAo que essa argumentação nos leva? Embora não se pretenda científica, ela ajuda a pensar na hipótese que introduzi no início. Pode ocorrer de vermos novas gerações terem um “achatamento” cultural ainda maior do que a minha geração (“millennials”, para usarmos a classificação do marketing).\nNão que seja simplesmente bom ou ruim. Nada na realidade é tão simplista. Comércio, relações entre países e globalização são sobre padronização, “achatamentos” e sobre falamos a mesma língua, literal e metaforicamente. A própria História talvez seja um conflito por homogeneização cultural — seja via hard power (guerras, dominação etc.) ou soft power (influência cultural, religião, costumes etc.), até para nos entendermos uns aos outros e não parecermos alienígenas em um mesmo planeta, o que suspeito que possa ter ocorrido num passado remoto.\nNo entanto, de outro ponto de vista, isso inevitavelmente implica em perda de diversidade cultural, de identidade e outras consequências desconhecidas. No extremo, pode levar todos a viverem, comportarem-se, falarem e a pensarem da mesma forma — ou de forma muito similar, o que em certa medida ocorre no “ocidente clássico” (Europa e EUA).\n\nOutro estudo bastante recente, aliás, vai nessa linha. Pesquisadores do Instituto Max Planck, na Alemanha, detectaram um aumento “abrupto” no uso de palavras geradas pelo ChatGPT — e isso em inglês. Estão na lista “delve”, “comprehend”, “boast”, “swift” e “meticulous” (respectivamente, “aprofundar”, “compreender”, “gabar-se/ostentar”, “veloz” e “meticuloso”, em tradução livre, mas que podem não captar as nuances dos originais em inglês).\nSão evidências empíricas de que a linguagem gerada por IA pode estar moldando a comunicação falada por nós com implicações desconhecidas para a diversidade cultural e linguística.\nPara chegar a tal conclusão, a pesquisa analisou 740.249 horas de discurso humano, de 360.445 palestras acadêmicas do YouTube e 771.591 episódios de podcast em diversas disciplinas.\nO estudo quantificou as preferências de palavras do ChatGPT e, em seguida, comparou as distribuições de frequência de palavras em textos humanos com suas versões editadas pelo ChatGPT.\nFoi observado que a influência linguística dos LLM é presente na fala de early adopters (adotantes iniciais), como pessoas da academia, da ciência e da tecnologia. Mas se estende também a outros domínios, como negócios. E o comportamento não ocorre só em falas roteirizadas, mas em conversas informais, como nos podcasts.\nNão se sabe exatamente o que leva a essa adoção de termos do GPT na fala, segundo os pesquisadores. Pode ser imitação direta, maior facilidade cognitiva de lembrar ou algo mais profundo e desconhecido do processo cognitivo humano.\nO estudo levanta preocupações sobre a homogeneização cultural (o “achatamento”). Um efeito interessante (vale um artigo futuro) é no chamado “colapso do modelo”: a degradação da qualidade de IAs generativas, por serem cada vez mais treinadas em dados gerados por elas mesmas.\nNa busca crescente por otimização de tudo, pode haver uma “redução da entropia”, tornando tudo mais e mais igual, a ponto de não haver mais variedade de dados. Isso limitaria os próprios dados de treinamento, fazendo-os serem menos “generativos” cada avanço. Em um extremo hipotético, LLMs se tornariam “determinísticos” a diversas entradas.\n\nSe enxergarmos isso como problema, como resolvê-lo? Não é uma questão trivial. Dado o uso crescente de LLMs e dado que, inevitavelmente, os dados disponíveis na web, livros ou em quaisquer outras mídias parecem ser em sua maioria em inglês — o que, repito, reflete um determinado tipo de cultura, jeito de se comunicar, de pensar e de viver —, não parece haver muita saída.\nO que pode mudar um pouco o cenário, e em alguma medida isso acontece de 2022 para cá — mas, novamente, dentro da disponibilidade de dados para treinamento —, é a inclusão de mais dados de outras línguas que não o inglês em datasets.\nUma terceira medida é, sim, o treinamento de LLMs com um peso maior para um idioma em detrimento de outros. É o que vem acontecendo em relação ao chinês, já que a China está em uma corrida geopolítica com os EUA para domínio em vários campos, entre eles a IA.\nHá relatos do DeepSeek, por exemplo, gerar saídas em chinês sem motivo aparente, em especial em tarefas difíceis. Tal comportamento pode ocorrer por haver uma maior quantidade de dados em chinês do que em inglês no pré-treinamento do modelo ou por características adicionadas no pós-treinamento, como no RLHF (“Reinforcement Learning from Human Feedback” ou “Aprendizagem por Reforço com Feedback Humano”, em tradução livre).\nEm relação ao português do Brasil, os LLMs da Amazônia IA e da Maritaca vão na mesma direção. Ainda não testei ambos a fundo, mas em uma comparação rápida com GPT, Claude e Gemini, notei que tanto o modelo Sabiá 3.1 quanto Sabiá 3 e Sabiazinho, da Maritaca, adotam nuances da escrita em português do Brasil que costumam exigir prompt engineering nos LLMs mainstream.\nUm exemplo rápido é quanto às construções frasais, que nos LLMs da moda tendem a se estender com gerúndios e seguir padrões facilmente encontrados em reports e artigos acadêmicos em inglês americano. Notei que eles ocorrem menos ou não ocorrem nos modelos da Maritaca. Vale mencionar outros exemplos como Bode ou Clarice, mas não os testei para ter uma impressão.\nA conjectura que fica é se, dentro de 3, 5 ou 10 anos — longo prazo para a IA, dado os seus avanços — ainda fará sentido querermos nuances de determinadas línguas nos LLMs. Porque muito mais pessoas já terão recorrido e estarão recorrendo a eles. E uma gama muito maior de pessoas já pode estar habituada a falar, a pensar e se comportar com base na escrita em inglês, ou seja, em todo o contexto cultural que o idioma carrega.\nEm outras palavras: se mais pessoas pensam e agem de maneira parecida, não irão buscar “mais do mesmo” em vez de ainda sentirem necessidade de nuances diferentes? Outros modos de registrar a fala e, portanto, o pensamento, não irão virar, quando muito, peça de museu, já que não haverá mais necessidade delas? É uma questão filosófica, que só o tempo responderá."
  }
]